# Red Neuronal MLP - ClasificaciÃ³n MNIST

Este proyecto implementa una red neuronal perceptrÃ³n multicapa (MLP) para clasificar dÃ­gitos escritos a mano del dataset MNIST. Se desarrollaron **4 versiones diferentes** para comparar el rendimiento entre implementaciones secuenciales y paralelas en Python y C.

## ğŸ“‹ DescripciÃ³n del Proyecto

La red neuronal implementada tiene la siguiente arquitectura:
- **Capa de entrada:** 784 neuronas (imÃ¡genes 28x28 pÃ­xeles)
- **Capa oculta:** 512 neuronas con activaciÃ³n ReLU
- **Capa de salida:** 10 neuronas con activaciÃ³n Softmax (dÃ­gitos 0-9)

El objetivo es entrenar la red para reconocer dÃ­gitos y comparar los tiempos de ejecuciÃ³n entre diferentes enfoques de implementaciÃ³n.

---

## ğŸš€ Versiones Implementadas

### 1. Python Secuencial (`python_secuencial/`)

ImplementaciÃ³n base en Python usando NumPy. Procesamiento completamente secuencial.

**Ejecutar:**
```bash
cd python_secuencial
python entrenamiento.py
```

**Archivos principales:**
- `verificar_mnist.py`: Carga los datos MNIST desde archivos `.gz`
- `preprocesamiento.py`: NormalizaciÃ³n y codificaciÃ³n one-hot
- `entrenamiento.py`: Entrenamiento secuencial de la red

---

### 2. C Secuencial (`c_secuencial/`)

ImplementaciÃ³n en C puro sin optimizaciones de paralelismo. Usa Ã¡lgebra lineal manual.

**Compilar y ejecutar:**
```bash
cd c_secuencial
gcc mlp.c -o mlp.exe -O3
./mlp.exe
```

**Optimizaciones:** `-O3` para optimizaciÃ³n del compilador

---

### 3. Python con Multiprocessing (`python_mp/`)

VersiÃ³n paralela usando `multiprocessing` de Python. Divide el dataset en lotes y los procesa en mÃºltiples cores.

**Ejecutar:**
```bash
cd python_mp
python mp_entrenamiento.py
```

**CaracterÃ­sticas:**
- Divide el entrenamiento entre mÃºltiples procesos
- Cada proceso calcula gradientes en paralelo
- Proceso principal agrega los gradientes y actualiza pesos

---

### 4. C con OpenMP (`c_openmp/`)

ImplementaciÃ³n en C usando OpenMP para paralelizaciÃ³n automÃ¡tica de bucles crÃ­ticos.

**Compilar y ejecutar:**
```bash
cd c_openmp
gcc mlp.c -o mlp_omp.exe -O3 -fopenmp
./mlp_omp.exe
```

**CaracterÃ­sticas:**
- ParalelizaciÃ³n de operaciones matriciales con `#pragma omp parallel for`
- Control del nÃºmero de hilos con `OMP_NUM_THREADS`

---

## ğŸ“ Estructura del Proyecto

```
proyecto/
â”œâ”€â”€ data/                      # Dataset MNIST (.gz)
â”‚   â”œâ”€â”€ train-images-idx3-ubyte.gz
â”‚   â”œâ”€â”€ train-labels-idx1-ubyte.gz
â”‚   â”œâ”€â”€ t10k-images-idx3-ubyte.gz
â”‚   â””â”€â”€ t10k-labels-idx1-ubyte.gz
â”œâ”€â”€ python_secuencial/         # VersiÃ³n Python secuencial
â”œâ”€â”€ python_mp/                 # VersiÃ³n Python con multiprocessing
â”œâ”€â”€ c_secuencial/              # VersiÃ³n C secuencial
â””â”€â”€ c_openmp/                  # VersiÃ³n C con OpenMP
```

---

## âš™ï¸ Requisitos

**Python:**
- Python 3.8+
- NumPy
- Matplotlib (para visualizaciÃ³n)

**C:**
- GCC (MinGW en Windows)
- Soporte OpenMP

---

## ğŸ“Š ComparaciÃ³n de Rendimiento

Cada versiÃ³n imprime el tiempo de ejecuciÃ³n al finalizar. Los resultados esperados:
1. **C Secuencial:** MÃ¡s rÃ¡pido que Python secuencial
2. **Python MP:** Mejora escalable segÃºn nÃºmero de cores
3. **C OpenMP:** MÃ¡ximo rendimiento con paralelizaciÃ³n optimizada